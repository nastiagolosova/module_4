{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "1. The goal of the project is to create a bank scoring model predicting whether or not the client will default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, f1_score\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing RANDOM_SEED to ensure the experiment can be replicated\n",
    "RANDOM_SEED = 42\n",
    "# fixing package version to ensure the experiment can be replicated\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/sf-dst-scoring/'\n",
    "train = pd.read_csv(DATA_DIR+'/train.csv')\n",
    "test = pd.read_csv(DATA_DIR+'test.csv')\n",
    "sample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining train and test together to process\n",
    "train['sample'] = 1 # mark train\n",
    "test['sample'] = 0 # mark test\n",
    "test['default'] = 0 # filling in \"default\" column with zeros as it is the value to be predicted\n",
    "\n",
    "data = test.append(train, sort=False).reset_index(drop=True) # join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client_id \n",
    "\n",
    "education - by levels\n",
    "\n",
    "sex -\n",
    "\n",
    "age - \n",
    "\n",
    "car - if owns or does not own a car\n",
    "\n",
    "car_type - if the car is of foreign bran\n",
    "\n",
    "decline_app_cnt - quantity of previously rejected applications\n",
    "\n",
    "good_work - if work is considered to be good\n",
    "\n",
    "bki_request_cnt - number of requests to credit bureau\n",
    "\n",
    "home_address - home address classifier\n",
    "\n",
    "work_address - work address classifier\n",
    "\n",
    "income - \n",
    "\n",
    "foreign_passport - if has or does not have a passport\n",
    "\n",
    "sna - borrower's connection with bank's clients\n",
    "\n",
    "first_time - how long ago information about the borrower was entered into the system\n",
    "\n",
    "score_bki - score according to credit bureu\n",
    "\n",
    "region_rating - \n",
    "\n",
    "app_date - when application was submitted (date)\n",
    "\n",
    "default - if the borrower has defaulted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Prepping DataÂ¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The only missing values are in the education column, let's see what unique values can be found there\n",
    "data.education.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.education.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's reasonable to suppose that all the clients will have at least school level education, plus it's also the most common\n",
    "# level, so I will fill in Nans with this value\n",
    "data.education.fillna('SCH', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Nans\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's convert sex, car_type, car and foreign_passport to binary\n",
    "bin_cols = ['sex', 'car', 'car_type', 'foreign_passport']\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in bin_cols:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "    \n",
    "   \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next column to preprocess is app_date\n",
    "# Because data format for app_date is object, let's change it to datetime first:\n",
    "date_string = data.app_date.to_list()\n",
    "dt_list = []\n",
    "for i in date_string:\n",
    "    i = datetime.strptime(i, '%d%b%Y')\n",
    "    dt_list.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and then replace the old values with the new ones\n",
    "data = data.assign(app_date=pd.Series(dt_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if it's worked\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because the model will only work with numbers I will transform this feature into a \"how many days ago\" ago feature:\n",
    "data['now'] = pd.to_datetime(\"now\") # create the column with current time to calculate the time since application\n",
    "data['days_ago'] = (data['now'] - data['app_date']).dt.days\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.education.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last column with string data is education. As education is represented as levels (school, undergraduate, graduate,\n",
    "# post-graduate, academic career), I believe I can map them as ordinal numbers:\n",
    "mapping = { \"SCH\" : 0,\"UGR\" : 1,\"GRD\":2,\"PGR\" : 3,\"ACD\":4}\n",
    "data['education'] = data.education.apply(lambda x : mapping[x])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the ease of use in exploratory analysis I will split the features into types:\n",
    "bin_cols = ['sex', 'car', 'car_type', 'foreign_passport', 'good_work']\n",
    "num_cols = ['age', 'decline_app_cnt', 'income', 'bki_request_cnt', 'score_bki', 'days_ago']\n",
    "cat_cols = ['education', 'home_address', 'work_address', 'sna', 'first_time', 'region_rating'] \n",
    "# even though first_time talks about how long ago client's data was first entered, I am putting it as a categorical\n",
    "# variable based on the values\n",
    "                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see how binary features correlate with the target:\n",
    "sex = data.sex.to_numpy()\n",
    "car = data.car.to_numpy()\n",
    "car_type = data.car_type.to_numpy()\n",
    "foreign_passport = data.foreign_passport.to_numpy()\n",
    "good_work = data.good_work.to_numpy()\n",
    "default = data.default.to_numpy()\n",
    "print(f'sex = {stats.pointbiserialr(default, sex)}, car = {stats.pointbiserialr(default, car)}, \\\n",
    "car_type = {stats.pointbiserialr(default, car_type)}, passport = {stats.pointbiserialr(default, foreign_passport)}, \\\n",
    "work = {stats.pointbiserialr(default, good_work)}' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, car_type and passport correlate with default the most. Let's see correlation of categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data[cat_cols].corr(method='spearman'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that home address and work address are correlated quite highly so we should only take one of them for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see the dependency between the target and categorical and binary viriables\n",
    "imp_cat = Series(mutual_info_classif(data[bin_cols + cat_cols], data['default'],\n",
    "                                     discrete_features =True), index = bin_cols + cat_cols)\n",
    "imp_cat.sort_values(inplace = True)\n",
    "imp_cat.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see  there is a greater dependency between sna, first_time, home_adress, region_rating and education with the target. \n",
    "I assume sna is related to having a possible co-signer in the same bank, first_time to having a longer/shorter credit history, education can help predict the level of income, and as far as home address/region_rating goes it may be connected with residing in more expensive/cheaper areas which signals a higher/lower income as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see if numerical data is distributed normally:\n",
    "for i in data[num_cols]:\n",
    "    plt.figure()\n",
    "    sns.distplot(data[i], kde = False, rug=False)\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check if there are outliers:\n",
    "def iqr_outliers(s): \n",
    "    q75, q25 = np.percentile(s, [75, 25], axis=0)\n",
    "    iqr = q75 - q25\n",
    "    lower_bound = q25 - 1.5 * iqr\n",
    "    upper_bound = q75 + 1.5 * iqr\n",
    "    return ~((s < lower_bound) | (s > upper_bound)).any(axis=1)\n",
    "# data[iqr_outliers(data[['age', 'decline_app_cnt', 'income', 'bki_request_cnt', 'score_bki', \\\n",
    "#                        'region_rating','sna', 'first_time', 'days_ago']])]\n",
    "# there turned to be a lot of them and eliminating outliers led to deleting about a half of the dataset, so it doesn't look\n",
    "# like a good solution to me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use logarithm to make distribution more normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data[num_cols]:\n",
    "    data[i] = np.log1p(data[i].abs())\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.distplot(data[i][data[i] > 0].dropna(), kde = False, rug=False)\n",
    "    plt.title(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking correlation of numerical variables:\n",
    "sns.heatmap(data[num_cols].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[num_cols].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Score_bki is somewhat correlated with decline_app_cnt and bki_request_cnt, but the numbers are pretty low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the dependency between numerical data and target:\n",
    "imp_num = Series(f_classif(data[num_cols], data['default'])[0], index = num_cols)\n",
    "imp_num.sort_values(inplace = True)\n",
    "imp_num.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no question as to why the greatest dependency exists between the score of the credit bureau and the number of declined applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preparing data for ML**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop datetime data\n",
    "data.drop(['app_date', 'now'], axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test dropping unnecessary columns\n",
    "train_data = data.query('sample == 1').drop(['sample', 'client_id'], axis=1)  # train\n",
    "test_data = data.query('sample == 0').drop(['sample', 'default'], axis=1)     # test\n",
    "\n",
    "# Saving client id from test for submission\n",
    "id_test = test_data['client_id']\n",
    "\n",
    "# deleting client id from test\n",
    "test_data.drop(['client_id'], axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing train_data\n",
    "X_num_train = StandardScaler().fit_transform(train_data[num_cols].values)\n",
    "\n",
    "\n",
    "# Standardizing test_data\n",
    "X_num_test = StandardScaler().fit_transform(test_data[num_cols].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting categorical data\n",
    "\n",
    "# train\n",
    "df_cat_train = train_data.drop([\"default\"], axis = 1)\n",
    "df_cat_train.drop(num_cols, axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# test\n",
    "df_cat_test = test_data.drop(num_cols, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining together binary, numerical and categorical data\n",
    "\n",
    "# train\n",
    "X_1 = np.hstack([X_num_train, df_cat_train.values])\n",
    "\n",
    "# test\n",
    "X_t_1 = np.hstack([X_num_test, df_cat_test.values])\n",
    "\n",
    "# target\n",
    "y_1 = train_data['default'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into reain and test for validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_1, y_1, test_size=0.20, shuffle = True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C = 10, random_state=RANDOM_SEED)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "probs = model.predict_proba(X_test)\n",
    "probs = probs[:,1]\n",
    "\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, probs)\n",
    "roc_auc = roc_auc_score(y_test, probs)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([0, 1], label='Baseline', linestyle='--')\n",
    "plt.plot(fpr, tpr, label = 'Regression')\n",
    "plt.title('Logistic Regression ROC AUC = %0.3f' % roc_auc)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eliminating less relevant features didn't do anything for the model\n",
    "confusion matrix classifies many defaulting clients as non-defaulting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ÐÐ°Ð´Ð°Ð´Ð¸Ð¼ Ð¾Ð³ÑÐ°Ð½Ð¸ÑÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð¿Ð°ÑÐ°Ð¼ÐµÑÑÐ° ÑÐµÐ³ÑÐ»ÑÑÐ¸Ð·Ð°ÑÐ¸Ð¸\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Ð¡Ð¾Ð·Ð´Ð°Ð´Ð¸Ð¼ Ð³Ð¸Ð¿ÐµÑÐ¿Ð°ÑÐ°Ð¼ÐµÑÑÑ\n",
    "param_grid = [\n",
    "    {'penalty': ['l1'], 'C':[0.1, 1, 10], 'max_iter':[1000],'tol':[1e-5]},\n",
    "    {'penalty': ['l2'], 'C':[0.1, 1, 10], 'max_iter':[1000],'tol':[1e-5]},\n",
    "    {'penalty': ['none'], 'max_iter':[1000],'tol':[1e-5]},\n",
    "]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÑÐµÑÐºÑ Ð¿Ð¾Ð¸ÑÐºÐ° Ñ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ 5-ÐºÑÐ°ÑÐ½Ð¾Ð¹ Ð¿ÐµÑÐµÐºÑÐµÑÑÐ½Ð¾Ð¹ Ð¿ÑÐ¾Ð²ÐµÑÐºÐ¸\n",
    "clf = GridSearchCV(model, param_grid, cv=5, verbose=0)\n",
    "\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "# View best hyperparameters\n",
    "print('ÐÑÑÑÐµÐµ Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('ÐÑÑÑÐµÐµ C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = LogisticRegression(C= 10, class_weight='balanced', solver='liblinear', random_state=RANDOM_SEED)\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_2 = model.predict(X_test)\n",
    "probs_2 = model_2.predict_proba(X_test)\n",
    "probs_2 = probs_2[:,1]\n",
    "\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test, probs)\n",
    "roc_auc = roc_auc_score(y_test, probs)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot([0, 1], label='Baseline', linestyle='--')\n",
    "plt.plot(fpr, tpr, label = 'Regression')\n",
    "plt.title('Logistic Regression ROC AUC = %0.3f' % roc_auc)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though ROC AUC has grown, the number of correctly identified clients has decreased compared with the first one, so I will go with the first model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ÐÑÐ²Ð¾Ð´Ñ Ð´Ð»Ñ ÑÐµÐ±Ñ: ÑÐ»Ð¾Ð²Ð°ÑÑ Ñ Ð³Ð¸Ð¿ÐµÑÐ¿Ð°ÑÐ°Ð¼ÐµÑÑÐ°Ð¼Ð¸ Ñ ÑÐºÐ¾Ð¿Ð¸ÑÐ¾Ð²Ð°Ð»Ð° Ð¸Ð· ÑÐ»Ð°ÐºÐ°, Ð¸ ÑÐ¶Ðµ Ð¾Ð´Ð½Ð¾ ÑÐ¾Ð»ÑÐºÐ¾ Ð·Ð½Ð°ÑÐµÐ½Ð¸Ðµ Ð¡ ÑÐ¸Ð»ÑÐ½Ð¾ Ð¿Ð¾Ð²Ð»Ð¸ÑÐ»Ð¾ Ð½Ð° ÑÐµÐ·ÑÐ»ÑÑÐ°Ñ.\n",
    "ÐÑÑÐ°Ð»ÑÐ½ÑÐµ Ð¿Ð°ÑÐ°Ð¼ÐµÑÑÑ Ñ Ð½Ð°ÑÑÑÐ¾Ð¸Ð»Ð° Ð¿Ð¾ÑÐ»Ðµ ÑÑÐµÐ½Ð¸Ñ Ð´Ð¾ÐºÑÐ¼ÐµÐ½ÑÐ°ÑÐ¸Ð¸ Ð²ÑÑÑÐ½ÑÑ: class_weight='balanced' ÑÐ°Ðº ÐºÐ°Ðº Ð½ÐµÐ´ÐµÑÐ¾Ð»ÑÐ½ÑÑ ÐºÐ»Ð¸ÐµÐ½ÑÐ¾Ð² Ð½ÐµÐ¿ÑÐ¾Ð¿Ð¾ÑÑÐ¸Ð¾Ð½Ð°Ð»ÑÐ½Ð¾ Ð¼Ð½Ð¾Ð³Ð¾, solver='liblinear' ÑÐ°Ðº ÐºÐ°Ðº Ð¾Ð½ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·ÑÐµÑÑÑ Ð½Ðµ Ð´Ð»Ñ Ð¼ÑÐ»ÑÑÐ¸ÐºÐ»Ð°ÑÑÐ¾Ð²\n",
    "Ð¯ Ð²Ð¸Ð´ÐµÐ»Ð°, ÑÑÐ¾ Ð´ÑÑÐ³Ð¸Ðµ ÑÑÑÐ´ÐµÐ½ÑÑ Ð¸ÑÐ¿Ð¾Ð»ÑÐ·Ð¾Ð²Ð°Ð»Ð¸ ÑÐ¸ÑÑÑÐµ ÑÑÐ½ÐºÑÐ¸Ð¸, Ð½Ð¾ Ñ Ð½Ðµ ÑÐ¾Ð²ÑÐµÐ¼ Ð¿Ð¾Ð½ÑÐ»Ð° ÐºÐ°Ðº Ð¾Ð½Ð¸ ÑÐ°Ð±Ð¾ÑÐ°ÑÑ, Ð¸ Ð¿Ð¾ÑÐ»Ð° Ð¿Ð¾ Ð¼ÐµÑÐ¾Ð´Ñ ÑÑÐµÐ½Ð¸Ñ Ð´Ð¾ÐºÑÐ¼ÐµÐ½ÑÐ°ÑÐ¸Ð¸.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = model.predict_proba(X_t_1)[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'client_id': id_test, \n",
    "                            'default': predict_submission})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
